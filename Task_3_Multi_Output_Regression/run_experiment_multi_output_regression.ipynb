{"cells":[{"cell_type":"markdown","metadata":{"id":"qMZrbVLN22KT"},"source":["# Run experiment multi output regression\n","\n","\n","---\n","\n","\n","The aim of this script is to run the experiment in order to train a multioutput regression neural network to predict the size of cell parameters of different crystal structures. Users have to load the crystal structure dataset, read it, select which are the features to be used to train the model, as well as, which are the response variables. \n","\n","After that, dataset will be splitted in 80% for training and 20% for test dataset. Training dataset will be splitted again in 75% for training and 25% for validation, during the hyperparameters optimization. After that, the best hyperparameters will be used to fit agai the neural network on the full training dataset."]},{"cell_type":"markdown","metadata":{"id":"JOohr7VS5Sop"},"source":["## Import library"]},{"cell_type":"code","source":["pip install keras-tuner --upgrade"],"metadata":{"id":"NEPe4FyzlDkX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668266356975,"user_tz":-60,"elapsed":3001,"user":{"displayName":"LEONARDO SACCOTELLI","userId":"18413620544580082956"}},"outputId":"8d3d20d9-7ae4-4f62-b44b-3b9e64b74e2a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.3)\n","Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.9.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.18.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.50.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.19.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.38.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (2.14.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.2)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"UbOdIUj45VdH","executionInfo":{"status":"ok","timestamp":1668266370139,"user_tz":-60,"elapsed":5960,"user":{"displayName":"LEONARDO SACCOTELLI","userId":"18413620544580082956"}}},"outputs":[],"source":["import os\n","\n","# Data Manipulation\n","import numpy as np\n","import pandas as pd\n","from scipy.stats import reciprocal\n","\n","# Data Visualization\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","# TensorFlow / Keras \n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError \n","import keras_tuner as kt\n","import tensorflow as tf\n","\n","# Scikit-learn\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsY5B1yb2lkV"},"outputs":[],"source":["import warnings \n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"ndMdVy715c-T"},"source":["## Load the Data\n","\n","\n","---\n","\n","\n","User must enter the name of the path in which dataset is stored. After that, we will check if the directory exists and if it is empty or not."]},{"cell_type":"markdown","source":["### *Check directory and files*"],"metadata":{"id":"mgSB0kosJBP_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6TdWOLS5cYb"},"outputs":[],"source":["def read_dataset ():\n","  dataset = ''\n","  path_name = input('Enter the path name for dataset: ')\n","  path_name = '/content/' + path_name\n","\n","  if not os.path.exists(path_name):\n","      print('Error! Invalid path selected.')\n","  else:\n","      print(path_name + ' is a valid path.')\n","\n","      if not os.listdir(path_name):\n","        print(\"Warning! Empty directory.\")\n","      else:\n","        file_name = input('Enter the file name for dataset: ')\n","        dataset = pd.read_csv(path_name + '/' + file_name + '.csv', sep = ';', index_col = 'ID_Observations' )\n","  return dataset"]},{"cell_type":"markdown","metadata":{"id":"NgixnYkv5vPQ"},"source":["### *Load the dataset*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXVkwuHJ5yR7"},"outputs":[],"source":["y_coord_dataset = read_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8hd6CI8558r"},"outputs":[],"source":["print('y_coord_dataset shape: {}'.format(y_coord_dataset.shape))\n","print('\\n data types: \\n{}'.format(y_coord_dataset.dtypes))\n","print('\\ny_coord_dataset content: \\n')\n","y_coord_dataset"]},{"cell_type":"markdown","metadata":{"id":"u_XBPrEl6Tzp"},"source":["## Insert details on dataset features\n","\n","\n","---\n","\n","\n","Users have to specify which variables will be used as features and which will be response features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-6FLTa16jzc"},"outputs":[],"source":["def insert_dataset_structure_details(final_dataset):\n","    print('============================================================================')\n","    print('Insert dataset structure details');\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        use_volume = input('\\n1) Do you want to use volume as a feature in the experiment? [Y|N]: ');\n","        if use_volume.lower() == 'y':\n","          use_volume = True;\n","          break;\n","        elif use_volume.lower() == 'n':\n","          use_volume = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        use_total_n_peaks = input('\\n2) Do you want to use total_n_peaks as a feature in the experiment? [Y|N]: ');\n","        if use_total_n_peaks.lower() == 'y':\n","          use_total_n_peaks = True;\n","          break;\n","        elif use_total_n_peaks.lower() == 'n':\n","          use_total_n_peaks = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        use_max_peaks = input('\\n3) Do you want to use max_peaks as a feature in the experiment? [Y|N]: ');\n","        if use_max_peaks.lower() == 'y':\n","          use_max_peaks = True;\n","          break;\n","        elif use_max_peaks.lower() == 'n':\n","          use_max_peaks = False;\n","          break;\n","   \n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        a_is_response = input('\\n4) \"a\" is a response feature ? [Y|N]: ');\n","        if a_is_response.lower() == 'y':\n","          a_is_response = True;\n","          break;\n","        elif a_is_response.lower() == 'n':\n","          a_is_response = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        b_is_response = input('\\n5) \"b\" is a response feature ? [Y|N]: ');\n","        if b_is_response.lower() == 'y':\n","          b_is_response = True;\n","          break;\n","        elif b_is_response.lower() == 'n':\n","          b_is_response = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        c_is_response = input('\\n6) \"c\" is a response feature ? [Y|N]: ');\n","        if c_is_response.lower() == 'y':\n","          c_is_response = True;\n","          break;\n","        elif c_is_response.lower() == 'n':\n","          c_is_response = False;\n","          break;\n","\n","    print('============================================================================')\n","\n","    response_features_name = []\n","\n","    if not use_total_n_peaks:\n","      final_dataset.drop('Total_n_peaks', axis=1, inplace=True)\n","    \n","    if not use_max_peaks:\n","      final_dataset.drop('Max_peaks_position', axis=1, inplace=True)\n","\n","    if not use_volume:\n","      final_dataset.drop('Volume', axis=1, inplace=True)\n","    \n","    if not a_is_response:\n","      final_dataset.drop('a', axis=1, inplace=True)\n","    else:\n","      response_features_name.append('a')\n","    \n","    if not b_is_response:\n","      final_dataset.drop('b', axis=1, inplace=True)\n","    else:\n","      response_features_name.append('b')\n","    \n","    if not c_is_response:\n","      final_dataset.drop('c', axis=1, inplace=True)  \n","    else:\n","      response_features_name.append('c')\n","\n","    final_dataset.drop('Crystal_Structure_Type', axis=1, inplace=True)\n","\n","    return final_dataset, response_features_name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbFBEeYD9vvU"},"outputs":[],"source":["final_dataset_for_experiment, response_features_name = insert_dataset_structure_details(y_coord_dataset.copy())\n","print('The response features for this crystal structure are: {}'.format(response_features_name))\n","print('The final dataset with features is:\\n')\n","final_dataset_for_experiment"]},{"cell_type":"markdown","metadata":{"id":"d74ocequF0h_"},"source":["## Splitting data for regression task"]},{"cell_type":"markdown","metadata":{"id":"RSXGeAoeFIbW"},"source":["### *Separating Input Features and Output Features*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUW84c9ZD84C"},"outputs":[],"source":["x = final_dataset_for_experiment[final_dataset_for_experiment.columns.difference(response_features_name)]\n","print('The dataset has the following number of input features: {:d}'.format(x.shape[1]))\n","print('Input features to be used for training are: ')\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5R9oCFUGQe8"},"outputs":[],"source":["y = final_dataset_for_experiment[response_features_name]\n","print('The dataset has the following number of output features: {:d}'.format(y.shape[1]))\n","print('Output features are:')\n","y"]},{"cell_type":"markdown","metadata":{"id":"M6D5Y_vll4o_"},"source":["### *Splitting the dataset into training set, validation set and test set*\n","We use 80% of the original dataset as training dataset and the remaining 20% to test the model.\n","The training set (80%) is splitted again in training dataset (75%) and validation dataset (25%). \n","\n","**random_state messo per riproducibilità**\n","**da cancellare**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNiKQ7fql4R4"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"]},{"cell_type":"code","source":["x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=8)"],"metadata":{"id":"3fL2xqBy4CQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZlw3KbIntcR"},"outputs":[],"source":["print('Training-Validation-Test dataset shape')\n","print('------------------------------------------------------------------------')\n","print('- The training set has the following number of observations: {:d}'.format(y_train.shape[0]))\n","print('- The validation set has the following number of observations: {:d}'.format(y_val.shape[0]))\n","print('- The test set has the following number of observations: {:d}'.format(y_test.shape[0]))"]},{"cell_type":"markdown","source":["## Training multi-output regression neural network model\n","\n","---\n","\n","After splitting the data into training and testing sets, it's time to train our neural network model. \n","\n","***Keras models accept three types of inputs:***\n","* NumPy arrays, just like Scikit-Learn and many other Python-based libraries. This is a good option if your data fits in memory.\n","* TensorFlow Dataset objects. This is a high-performance option that is more suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed filesystem.\n","* Python generators that yield batches of data (such as custom subclasses of the keras.utils.Sequence class).***"],"metadata":{"id":"C_PHD3gFz-EA"}},{"cell_type":"markdown","source":["### *Define the neural network architectures and search space for hyperparameters*"],"metadata":{"id":"M67YnAZp0qmH"}},{"cell_type":"code","source":["def build_model(hp):\n","  model = Sequential()\n","\n","  # Optimize the number of hidden layers\n","  for i in range(hp.Int('num_layers', 1, 5)):\n","    model.add(Dense(units=hp.Int(f'units_{i}', min_value=50, max_value=500, step=25),\n","                    activation=hp.Choice(f'activation_{i}', ['relu',\n","                                                             'tanh',])))\n","  model.add(Dropout(rate=hp.Choice(f'drop_rate_layer_{i}',[0.0,0.1,0.2,\n","                                                             0.3,0.4,0.5,\n","                                                             0.6,0.7,0.8,0.9])))\n","\n","  # Adding the output layer (senza fuznione di attivazione, \n","  # dovremmo cambiare il numero di neuroni in base al numero di output)\n","  model.add(Dense(1))\n","\n","  # Define the optimizer learning rate as a hyperparameter.\n","  learning_rate = hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='log')\n","  model.compile(\n","      optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n","      loss='mean_squared_error',\n","      metrics=[RootMeanSquaredError(), MeanAbsoluteError(), MeanAbsolutePercentageError()],\n","      )\n","  return model"],"metadata":{"id":"j1yqGb1IGMhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["build_model(kt.HyperParameters())"],"metadata":{"id":"HvoEGrKTI7Zb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner = kt.RandomSearch(\n","    hypermodel=build_model,\n","    objective=kt.Objective('val_root_mean_squared_error', direction='min'),\n","    max_trials=5,\n","    executions_per_trial=5,\n","    overwrite=True,\n","    distribution_strategy=tf.distribute.MirroredStrategy(),\n","    directory='neural-network-opt-2',\n","    project_name='cubic-opt-neural-network'\n",")"],"metadata":{"id":"_Hvexa5iJaih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search_space_summary()"],"metadata":{"id":"4jeDsMrPr9_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search(x_train, y_train, \n","             epochs=100, \n","             validation_data=(x_val, y_val)\n","             )\n","             #callbacks=[tf.keras.callbacks.EarlyStopping(\n","                 #monitor='val_root_mean_squared_error', patience=5)]"],"metadata":{"id":"8kti9ysCsWUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.results_summary()"],"metadata":{"id":"jFBZfbUAuuwP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(tuner.get_best_hyperparameters()[0].values)"],"metadata":{"id":"rpwukeut8Q_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = tuner.get_best_models(num_models=1)[0]"],"metadata":{"id":"ms8dS8bfzTDk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n","best_model.fit(x_train, y_train, batch_size=32, epochs=100, initial_epoch=0)"],"metadata":{"id":"z6zMXut908nH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model.summary()\n","best_model.evaluate(x_test,y_test)"],"metadata":{"id":"EHPVY7Vb1aBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot regression results"],"metadata":{"id":"LfJ6aW0bRK9V"}},{"cell_type":"markdown","source":["### *Perfect fit plot*\n","*Perfect fit plot* will display a straight black line meaning real observations value are equals to predicted values, and a blue points which will represent the observations. We will plot real observations value again predicted values."],"metadata":{"id":"7QUiaSOgRR82"}},{"cell_type":"code","source":["import random\n","trX = 0.5 * np.random.randn(1500) * 0.25 +1\n","trY = 0.8* np.random.randn(*trX.shape) * 0.33 +1\n","df = pd.DataFrame({'Obs_a':trX,'pred_a': trY,'Obs_b':trX,'pred_b': trY,'Obs_c':trX,'pred_c': trY})\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"0bZieC5SMmUH","executionInfo":{"status":"ok","timestamp":1668266384294,"user_tz":-60,"elapsed":11,"user":{"displayName":"LEONARDO SACCOTELLI","userId":"18413620544580082956"}},"outputId":"58d59a53-0385-486e-b0e6-0e7e918c4870"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         Obs_a    pred_a     Obs_b    pred_b     Obs_c    pred_c\n","0     0.996720  1.416517  0.996720  1.416517  0.996720  1.416517\n","1     0.809764  0.979116  0.809764  0.979116  0.809764  0.979116\n","2     0.999454  0.611874  0.999454  0.611874  0.999454  0.611874\n","3     1.339207  1.154983  1.339207  1.154983  1.339207  1.154983\n","4     1.140176  0.536163  1.140176  0.536163  1.140176  0.536163\n","...        ...       ...       ...       ...       ...       ...\n","1495  1.200987  1.209838  1.200987  1.209838  1.200987  1.209838\n","1496  1.048898  0.753572  1.048898  0.753572  1.048898  0.753572\n","1497  1.105199  0.732943  1.105199  0.732943  1.105199  0.732943\n","1498  0.892052  0.714583  0.892052  0.714583  0.892052  0.714583\n","1499  0.963448  1.449351  0.963448  1.449351  0.963448  1.449351\n","\n","[1500 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-9d5d98c5-1079-44a9-9458-7c59850ebaf6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Obs_a</th>\n","      <th>pred_a</th>\n","      <th>Obs_b</th>\n","      <th>pred_b</th>\n","      <th>Obs_c</th>\n","      <th>pred_c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.996720</td>\n","      <td>1.416517</td>\n","      <td>0.996720</td>\n","      <td>1.416517</td>\n","      <td>0.996720</td>\n","      <td>1.416517</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.809764</td>\n","      <td>0.979116</td>\n","      <td>0.809764</td>\n","      <td>0.979116</td>\n","      <td>0.809764</td>\n","      <td>0.979116</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.999454</td>\n","      <td>0.611874</td>\n","      <td>0.999454</td>\n","      <td>0.611874</td>\n","      <td>0.999454</td>\n","      <td>0.611874</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.339207</td>\n","      <td>1.154983</td>\n","      <td>1.339207</td>\n","      <td>1.154983</td>\n","      <td>1.339207</td>\n","      <td>1.154983</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.140176</td>\n","      <td>0.536163</td>\n","      <td>1.140176</td>\n","      <td>0.536163</td>\n","      <td>1.140176</td>\n","      <td>0.536163</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1495</th>\n","      <td>1.200987</td>\n","      <td>1.209838</td>\n","      <td>1.200987</td>\n","      <td>1.209838</td>\n","      <td>1.200987</td>\n","      <td>1.209838</td>\n","    </tr>\n","    <tr>\n","      <th>1496</th>\n","      <td>1.048898</td>\n","      <td>0.753572</td>\n","      <td>1.048898</td>\n","      <td>0.753572</td>\n","      <td>1.048898</td>\n","      <td>0.753572</td>\n","    </tr>\n","    <tr>\n","      <th>1497</th>\n","      <td>1.105199</td>\n","      <td>0.732943</td>\n","      <td>1.105199</td>\n","      <td>0.732943</td>\n","      <td>1.105199</td>\n","      <td>0.732943</td>\n","    </tr>\n","    <tr>\n","      <th>1498</th>\n","      <td>0.892052</td>\n","      <td>0.714583</td>\n","      <td>0.892052</td>\n","      <td>0.714583</td>\n","      <td>0.892052</td>\n","      <td>0.714583</td>\n","    </tr>\n","    <tr>\n","      <th>1499</th>\n","      <td>0.963448</td>\n","      <td>1.449351</td>\n","      <td>0.963448</td>\n","      <td>1.449351</td>\n","      <td>0.963448</td>\n","      <td>1.449351</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1500 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d5d98c5-1079-44a9-9458-7c59850ebaf6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9d5d98c5-1079-44a9-9458-7c59850ebaf6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9d5d98c5-1079-44a9-9458-7c59850ebaf6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def plot_perfect_fit(df, output_names, title_fig):\n","\n","  n_output = df.shape[1]\n","  \n","  fig = make_subplots(\n","      rows=1, cols= round(n_output/2),\n","      subplot_titles=['<b>' + name_output + '</b>' for name_output in output_names],\n","  )\n","\n","  max_lim_axis = round(max(df.max(axis=0))+1)\n","\n","  min_lim_axis = round(min(df.min(axis=0)))\n","  if min_lim_axis > 0:\n","    min_lim_axis = 0\n","  \n","  fit_point = np.linspace(0, max_lim_axis, max_lim_axis)\n","\n","  j = 1\n","\n","  for i in range(0,n_output,2):\n","    obs = df.iloc[:, i].to_numpy()\n","    pred = df.iloc[:, i+1].to_numpy()\n","\n","    fig.add_trace(go.Scatter(x=obs, y=pred, mode='markers', marker_color='#1F77B4', \n","                             marker_size=8, name='Observations'), row=1, col=j)\n","    \n","    fig.add_trace(go.Scatter(x=fit_point, y=fit_point, mode='lines', \n","                             line={'color': 'black'}, name='Perfect prediction'),\n","                   row=1, col=j)\n","    \n","    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', \n","                      showline=True, linewidth=2, linecolor='black', mirror=True,\n","                      title_text='True response', range=[min_lim_axis, max_lim_axis])\n","    \n","    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', \n","                      showline=True, linewidth=2, linecolor='black', mirror=True,\n","                      title_text='Predicted response', range=[min_lim_axis, max_lim_axis])\n","    if j > 1:\n","      fig.update_traces(row=1, col=j, showlegend=False)\n","    \n","    fig.layout.annotations[j-1].update(font=dict(size=20))\n","\n","    j+=1\n","\n","  fig.update_layout(\n","      template='simple_white',\n","      width=1780,\n","      height=650,\n","      title_text='<b>'+title_fig+'</b>',\n","      title_x=0.5, \n","      font=dict(size=16), \n","      legend_tracegroupgap=360,\n","      legend=dict(\n","          font=dict(size=16),\n","          bordercolor=\"Black\",\n","          borderwidth=2\n","          )\n","  )\n","\n","  fig.show()"],"metadata":{"id":"q_MRSdU0RW88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_perfect_fit(df,['a','b','c'], 'Cube')"],"metadata":{"id":"YTUmUCMoRxiW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### *Residual bar plot*\n","*Residual bar plot* will display blue points which represent the real observations, the yellow points which are predicted observations and the red bar which are the residual values between real and predicted values."],"metadata":{"id":"brjLa_i4MjeE"}},{"cell_type":"code","source":["def plot_residual_bar(df, output_names, title_fig):\n","\n","  n_observations = df.shape[0]\n","  n_output = df.shape[1]\n","  \n","  fig = make_subplots(\n","      rows=1, cols= round(n_output/2),\n","      subplot_titles=['<b>' + name_output + '</b>' for name_output in output_names],\n","  )\n","\n","  max_lim_axis = round(max(df.max(axis=0))+1)\n","\n","  min_lim_axis = round(min(df.min(axis=0)))\n","  if min_lim_axis > 0:\n","    min_lim_axis = 0\n","  \n","  index_row = np.linspace(0, n_observations, n_observations)\n","\n","  j = 1\n","  show_error_legend_bar = True\n","\n","  for i in range(0,n_output,2):\n","    param_df = df.iloc[:, [i, i+1]]\n","    param_df = param_df.sort_values(by=param_df.columns[0])\n","    \n","    obs = param_df.iloc[:, 0].to_numpy()\n","    pred = param_df.iloc[:, 1].to_numpy()\n","\n","    for k in range(1, n_observations):\n","      fig.add_trace(go.Scatter(x=[k,k], y=[obs[k], pred[k]], name=\"Error\", \n","                                mode='lines', line={'color': '#D62728', 'width':1},\n","                               showlegend=show_error_legend_bar), row=1, col=j)\n","      if show_error_legend_bar:\n","        show_error_legend_bar=False\n","\n","    fig.add_trace(go.Scatter(x=index_row, y=obs, mode='markers', marker_color='#1F77B4', \n","                             marker_size=8, name='True'), row=1, col=j)\n","    \n","    fig.add_trace(go.Scatter(x=index_row, y=pred, mode='markers', marker_color='#FF7F0E', \n","                             marker_size=8, name='Predicted'), row=1, col=j)\n","        \n","    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', \n","                      showline=True, linewidth=2, linecolor='black', mirror=True,\n","                      title_text='Record number', range=[0, n_observations])\n","    \n","    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', \n","                      showline=True, linewidth=2, linecolor='black', mirror=True,\n","                      title_text='Response', range=[min_lim_axis, max_lim_axis])\n","    if j > 1:\n","      fig.update_traces(row=1, col=j, showlegend=False)\n","    \n","    fig.layout.annotations[j-1].update(font=dict(size=20))\n","\n","    j+=1\n","\n","  fig.update_layout(\n","      template='simple_white',\n","      width=1780,\n","      height=650,\n","      title_text='<b>'+title_fig+'</b>',\n","      title_x=0.5, \n","      font=dict(size=16), \n","      legend_tracegroupgap=360,\n","      legend=dict(\n","          font=dict(size=16),\n","          bordercolor=\"Black\",\n","          borderwidth=2\n","          )\n","  )\n","\n","  fig.show()"],"metadata":{"id":"okGKCAhsienR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_residual_bar(df, ['a','b','c'],'cube')"],"metadata":{"id":"8kWqwsshV3_j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### *Compare observations plot*"],"metadata":{"id":"QHqqjs9Qu2PZ"}},{"cell_type":"code","source":["def plot_compare_observations(df, output_names, title_fig):\n","\n","  n_observations = df.shape[0]\n","  n_output = df.shape[1]\n","  \n","  fig = make_subplots(\n","      rows=round(n_output/2), cols=1,\n","      subplot_titles=['<b>' + name_output + '</b>' for name_output in output_names],\n","  )\n","\n","  max_lim_axis = round(max(df.max(axis=0))+1)\n","\n","  min_lim_axis = round(min(df.min(axis=0)))\n","  if min_lim_axis > 0:\n","    min_lim_axis = 0\n","  \n","  index_row = np.linspace(0, n_observations, n_observations)\n","\n","  j = 1\n","\n","  for i in range(0,n_output,2):\n","    obs = df.iloc[:, i].to_numpy()\n","    pred = df.iloc[:, i+1].to_numpy()\n","\n","    fig.add_trace(go.Scatter(x=index_row, y=obs, \n","                             mode='lines', line={'color': '#1F77B4', 'width':1},\n","                             name='True'), row=j, col=1)\n","    \n","    fig.add_trace(go.Scatter(x=index_row, y=pred, \n","                             mode='lines', line={'color': '#FF7F0E', 'width':1}, \n","                             name='Predicted'),row=j, col=1)\n","    \n","    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', \n","                      showline=True, linewidth=2, linecolor='black', mirror=True,\n","                      title_text='Record number', range=[0, n_observations])\n","    \n","    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey', \n","                      showline=True, linewidth=2, linecolor='black', mirror=True,\n","                      title_text='Response', range=[min_lim_axis, max_lim_axis])\n","    if j > 1:\n","      fig.update_traces(row=j, col=1, showlegend=False)\n","    \n","    fig.layout.annotations[j-1].update(font=dict(size=20))\n","\n","    j+=1\n","\n","  fig.update_layout(\n","      template='simple_white',\n","      width=1780,\n","      height=1500,\n","      title_text='<b>'+title_fig+'</b>',\n","      title_x=0.5, \n","      font=dict(size=16), \n","      legend_tracegroupgap=360,\n","      legend=dict(\n","          font=dict(size=16),\n","          bordercolor=\"Black\",\n","          borderwidth=2\n","          )\n","  )\n","\n","  fig.show()"],"metadata":{"id":"NpaRXD4Qu2bT","executionInfo":{"status":"ok","timestamp":1668266513070,"user_tz":-60,"elapsed":242,"user":{"displayName":"LEONARDO SACCOTELLI","userId":"18413620544580082956"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["plot_compare_observations(df, ['a','b','c'], 'cube')"],"metadata":{"id":"fxrVocMZTpEc"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["ndMdVy715c-T","mgSB0kosJBP_","NgixnYkv5vPQ","u_XBPrEl6Tzp","d74ocequF0h_","RSXGeAoeFIbW","M6D5Y_vll4o_","C_PHD3gFz-EA","M67YnAZp0qmH"],"provenance":[],"authorship_tag":"ABX9TyPlOj8BVyoGY1oPxpD5ATEi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}