{"cells":[{"cell_type":"markdown","metadata":{"id":"qMZrbVLN22KT"},"source":["# Run experiment multi output regression\n","\n","\n","---\n","\n","\n","The aim of this script is to run the experiment in order to train a multioutput regression neural network to predict the size of cell parameters of different crystal structures. Users have to load the crystal structure dataset, read it, select which are the features to be used to train the model, as well as, which are the response variables. \n","\n","After that, dataset will be splitted in 80% for training and 20% for test dataset. Repeated K-fold cross validation will be used with *k* and *n* equals to 10. Hyperparameters optimization will be also used. "]},{"cell_type":"markdown","metadata":{"id":"JOohr7VS5Sop"},"source":["## Import library"]},{"cell_type":"code","source":["pip install keras-tuner --upgrade"],"metadata":{"id":"NEPe4FyzlDkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbOdIUj45VdH"},"outputs":[],"source":["import os\n","\n","# Data Manipulation\n","import numpy as np\n","import pandas as pd\n","from scipy.stats import reciprocal\n","\n","# Data Visualization\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# TensorFlow / Keras \n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError \n","import kerastuner as kt\n","import tensorflow as tf\n","\n","# Scikit-learn\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsY5B1yb2lkV"},"outputs":[],"source":["import warnings \n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"ndMdVy715c-T"},"source":["## Load the Data\n","\n","\n","---\n","\n","\n","User must enter the name of the path in which dataset is stored. After that, we will check if the directory exists and if it is empty or not."]},{"cell_type":"markdown","source":["### *Check directory and files*"],"metadata":{"id":"mgSB0kosJBP_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6TdWOLS5cYb"},"outputs":[],"source":["def read_dataset ():\n","  dataset = ''\n","  path_name = input('Enter the path name for dataset: ')\n","  path_name = '/content/' + path_name\n","\n","  if not os.path.exists(path_name):\n","      print('Error! Invalid path selected.')\n","  else:\n","      print(path_name + ' is a valid path.')\n","\n","      if not os.listdir(path_name):\n","        print(\"Warning! Empty directory.\")\n","      else:\n","        file_name = input('Enter the file name for dataset: ')\n","        dataset = pd.read_csv(path_name + '/' + file_name + '.csv', sep = ';', index_col = 'ID_Observations' )\n","  return dataset"]},{"cell_type":"markdown","metadata":{"id":"NgixnYkv5vPQ"},"source":["### *Load the dataset*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXVkwuHJ5yR7"},"outputs":[],"source":["y_coord_dataset = read_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8hd6CI8558r"},"outputs":[],"source":["print('y_coord_dataset shape: {}'.format(y_coord_dataset.shape))\n","print('\\n data types: \\n{}'.format(y_coord_dataset.dtypes))\n","print('\\ny_coord_dataset content: \\n')\n","y_coord_dataset"]},{"cell_type":"markdown","metadata":{"id":"u_XBPrEl6Tzp"},"source":["## Insert details on dataset features\n","\n","\n","---\n","\n","\n","Users have to specify which variables will be used as features and which will be response features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-6FLTa16jzc"},"outputs":[],"source":["def insert_dataset_structure_details(final_dataset):\n","    print('============================================================================')\n","    print('Insert dataset structure details');\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        use_volume = input('\\n1) Do you want to use volume as a feature in the experiment? [Y|N]: ');\n","        if use_volume.lower() == 'y':\n","          use_volume = True;\n","          break;\n","        elif use_volume.lower() == 'n':\n","          use_volume = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        use_total_n_peaks = input('\\n2) Do you want to use total_n_peaks as a feature in the experiment? [Y|N]: ');\n","        if use_total_n_peaks.lower() == 'y':\n","          use_total_n_peaks = True;\n","          break;\n","        elif use_total_n_peaks.lower() == 'n':\n","          use_total_n_peaks = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        use_max_peaks = input('\\n3) Do you want to use max_peaks as a feature in the experiment? [Y|N]: ');\n","        if use_max_peaks.lower() == 'y':\n","          use_max_peaks = True;\n","          break;\n","        elif use_max_peaks.lower() == 'n':\n","          use_max_peaks = False;\n","          break;\n","   \n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        a_is_response = input('\\n4) \"a\" is a response feature ? [Y|N]: ');\n","        if a_is_response.lower() == 'y':\n","          a_is_response = True;\n","          break;\n","        elif a_is_response.lower() == 'n':\n","          a_is_response = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        b_is_response = input('\\n5) \"b\" is a response feature ? [Y|N]: ');\n","        if b_is_response.lower() == 'y':\n","          b_is_response = True;\n","          break;\n","        elif b_is_response.lower() == 'n':\n","          b_is_response = False;\n","          break;\n","\n","    while 1:\n","        print('----------------------------------------------------------------------------')\n","        c_is_response = input('\\n6) \"c\" is a response feature ? [Y|N]: ');\n","        if c_is_response.lower() == 'y':\n","          c_is_response = True;\n","          break;\n","        elif c_is_response.lower() == 'n':\n","          c_is_response = False;\n","          break;\n","\n","    print('============================================================================')\n","\n","    response_features_name = []\n","\n","    if not use_total_n_peaks:\n","      final_dataset.drop('Total_n_peaks', axis=1, inplace=True)\n","    \n","    if not use_max_peaks:\n","      final_dataset.drop('Max_peaks_position', axis=1, inplace=True)\n","\n","    if not use_volume:\n","      final_dataset.drop('Volume', axis=1, inplace=True)\n","    \n","    if not a_is_response:\n","      final_dataset.drop('a', axis=1, inplace=True)\n","    else:\n","      response_features_name.append('a')\n","    \n","    if not b_is_response:\n","      final_dataset.drop('b', axis=1, inplace=True)\n","    else:\n","      response_features_name.append('b')\n","    \n","    if not c_is_response:\n","      final_dataset.drop('c', axis=1, inplace=True)  \n","    else:\n","      response_features_name.append('c')\n","\n","    final_dataset.drop('Crystal_Structure_Type', axis=1, inplace=True)\n","\n","    return final_dataset, response_features_name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbFBEeYD9vvU"},"outputs":[],"source":["final_dataset_for_experiment, response_features_name = insert_dataset_structure_details(y_coord_dataset.copy())\n","print('The response features for this crystal structure are: {}'.format(response_features_name))\n","print('The final dataset with features is:\\n')\n","final_dataset_for_experiment"]},{"cell_type":"markdown","metadata":{"id":"d74ocequF0h_"},"source":["## Splitting data for regression task"]},{"cell_type":"markdown","metadata":{"id":"RSXGeAoeFIbW"},"source":["### *Separating Input Features and Output Features*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUW84c9ZD84C"},"outputs":[],"source":["x = final_dataset_for_experiment[final_dataset_for_experiment.columns.difference(response_features_name)]\n","print('The dataset has the following number of input features: {:d}'.format(x.shape[1]))\n","print('Input features to be used for training are: ')\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5R9oCFUGQe8"},"outputs":[],"source":["y = final_dataset_for_experiment[response_features_name]\n","print('The dataset has the following number of output features: {:d}'.format(y.shape[1]))\n","print('Output features are:')\n","y"]},{"cell_type":"markdown","metadata":{"id":"M6D5Y_vll4o_"},"source":["### *Splitting the dataset into training set and test set*\n","We use 80% of the original dataset as training dataset and the remaining 20% to test the model.\n","\n","**random_state messo per riproducibilit√†**\n","**da cancellare**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNiKQ7fql4R4"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZlw3KbIntcR"},"outputs":[],"source":["print('Training/Test dataset shape')\n","print('------------------------------------------------------------------------')\n","print('- The training set has the following number of observations: {:d}'.format(y_train.shape[0]))\n","print('- The test set has the following number of observations: {:d}'.format(y_test.shape[0]))"]},{"cell_type":"markdown","source":["## Training multi-output regression neural network model\n","\n","---\n","\n","After splitting the data into training and testing sets, it's time to train our neural network model. \n","\n","***Keras models accept three types of inputs:***\n","* NumPy arrays, just like Scikit-Learn and many other Python-based libraries. This is a good option if your data fits in memory.\n","* TensorFlow Dataset objects. This is a high-performance option that is more suitable for datasets that do not fit in memory and that are streamed from disk or from a distributed filesystem.\n","* Python generators that yield batches of data (such as custom subclasses of the keras.utils.Sequence class).***"],"metadata":{"id":"C_PHD3gFz-EA"}},{"cell_type":"markdown","source":["### *Define the neural network architectures and search space for hyperparameters*"],"metadata":{"id":"M67YnAZp0qmH"}},{"cell_type":"code","source":["def build_model(hp):\n","  model = Sequential()\n","\n","  # Optimize the number of hidden layers\n","  for i in range(hp.Int('num_layers', 1, 10)):\n","    model.add(Dense(units=hp.Int(f'units_{i}', min_value=50, max_value=500, step=25),\n","                    activation=hp.Choice(f'activation_{i}', ['relu', 'tanh'])))\n","\n","  # Adding the output layer (senza fuznione di attivazione, \n","  # dovremmo cambiare il numero di neuroni in base al numero di output)\n","  model.add(Dense(1))\n","\n","  # Define the optimizer learning rate as a hyperparameter.\n","  learning_rate = hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='log')\n","  model.compile(\n","      optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n","      loss='mean_squared_error',\n","      metrics=[RootMeanSquaredError()],\n","      )\n","  return model"],"metadata":{"id":"j1yqGb1IGMhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# funzione per plottare la learning curves\n","def plot_learning_curves(history):\n","  pd.DataFrame(history.history).plot(figsize=(8, 5))\n","  plt.grid(True)\n","  #plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n","  plt.show()"],"metadata":{"id":"ck4vgxT9LWrU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["build_model(kt.HyperParameters())"],"metadata":{"id":"HvoEGrKTI7Zb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner = kt.RandomSearch(\n","    hypermodel=build_model,\n","    objective=kt.Objective('val_loss', direction='min'),\n","    max_trials=2,\n","    executions_per_trial=5,\n","    overwrite=True,\n","    directory='neural-network-opt-2',\n","    project_name='cubic-opt-neural-network'\n",")"],"metadata":{"id":"_Hvexa5iJaih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search_space_summary()"],"metadata":{"id":"4jeDsMrPr9_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.search(x_train, y_train, \n","             epochs=10, \n","             validation_data=(x_test, y_test),\n","             callbacks=[tf.keras.callbacks.EarlyStopping(\n","                 monitor='val_loss', patience=5)])"],"metadata":{"id":"8kti9ysCsWUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner.results_summary()"],"metadata":{"id":"jFBZfbUAuuwP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(tuner.get_best_hyperparameters()[0].values)"],"metadata":{"id":"rpwukeut8Q_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = tuner.get_best_models(num_models=1)[0]"],"metadata":{"id":"ms8dS8bfzTDk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n","best_model.fit(x_train, y_train, batch_size=32, epochs=100, initial_epoch=0)"],"metadata":{"id":"z6zMXut908nH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model.summary()\n","best_model.evaluate(x_test,y_test)"],"metadata":{"id":"EHPVY7Vb1aBZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyNJOpEp5P5CwSXc15vIpZxm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}