{"cells":[{"cell_type":"markdown","metadata":{"id":"pyHJOD2bHw3U"},"source":["# Merging raw data from crystal dataset\n","\n","\n","---\n","\n","\n","The aim of this script is to merge in a more confortable way the huge raw dataset available. In particular, for each crystal structure (we have 7 different crystal structure), the releated dataset will be loaded from a large-text-file. As output of this script we want a dataframe (X) which collect all the spectrum position (from 0 to 90, increasing by 0.02) and 7 different dataframe (one for each crystal structure), which collect the releated intensity with respect the X position in the spectrum. Moreover, in each Y dataset, we collect also the cell paramenters size, which will be used as target features in future task. Lastly, dataset will be saved."]},{"cell_type":"markdown","metadata":{"id":"wt3u9-XoJf7-"},"source":["## Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"svVbGCt0GbiW"},"outputs":[],"source":["import os\n","from google.colab import files\n","\n","# Data Manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Data Visualization\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzkSzN_mw-T6"},"outputs":[],"source":["import warnings \n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"1Dccmk-CdTti"},"source":["## Create dataframes to store dataset \n","---\n","For each dataset, script will produce two different dataframe in output as followed:\n","*   ***x_coord_dataset***, which is a dataframe of size 1-by-4501  with information about the x-coord of the spectrum. In particular, we store point in the following interval [0,90] increasing by 0.02;\n","*   ***y_coord_dataset***, which is a datframe of size num_obs-by-4502 storing information about the recordered intensity, releated to each point stored in x-coord-dataset, with also id-observation\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nqoK0aUBfRud"},"source":["### *Create dataframe to store the x-coordinates of the spectrum for each observation*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0BVuw7PBdTIU"},"outputs":[],"source":["x_coord_dataset = pd.DataFrame(np.arange(0,90.02,0.02)).T\n","x_coord_dataset.columns = [f'x_{i}' for i in range(1,len(x_coord_dataset.T)+1)]   # Rename x_coord_dataset columns name\n","print('The x_coord_dataset has the following shape: ', x_coord_dataset.shape)     # Check the shape of x_coord_dataset\n","x_coord_dataset"]},{"cell_type":"markdown","metadata":{"id":"wm-CS9rxfd6S"},"source":["### *Create a dataframe to store the y-coordinates of the spectrum for each observation*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFC4gRBvfk9G"},"outputs":[],"source":["y_coord_dataset = pd.DataFrame(columns = [f'y_{i}' for i in range(1,4502)])\n","y_coord_dataset['ID_Observations'] = ''\n","y_coord_dataset"]},{"cell_type":"markdown","metadata":{"id":"8c3sb8AffliH"},"source":["### *Create dataframe to store additional information*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bshJK0HHflw7"},"outputs":[],"source":["additional_information_dataset = pd.DataFrame(columns=['ID_Observations', 'a', \n","                                                       'b', 'c', 'alpha', 'beta',\n","                                                       'gamma', 'Volume', \n","                                                       'Crystal_Structure_Type'])\n","additional_information_dataset"]},{"cell_type":"markdown","metadata":{"id":"4916x2WWz6JG"},"source":["## Load the data\n","\n","\n","---\n","\n","\n","User must enter the name of the path in which dataset is stored. After that, we will check if the directory exists and if it is empty or not."]},{"cell_type":"markdown","source":["### *Check directory and files*"],"metadata":{"id":"_vqxnU0fTWiN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JV3_61OdtIWA"},"outputs":[],"source":["UploadedFiles = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBH3Q0Pp_5Wc"},"outputs":[],"source":["path_name = input('Enter the path name for dataset: ')\n","path_name = '/content/' + path_name\n","dir_list = ''\n","\n","if not os.path.exists(path_name):\n","    print('Error! Invalid path selected.')\n","else:\n","    print(path_name + ' is a valid path.')\n","\n","    if not os.listdir(path_name):\n","      print(\"Warning! Empty directory.\")\n","    else:\n","      dir_list = os.listdir(path_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"toC_Hnqczioo"},"outputs":[],"source":["dir_list"]},{"cell_type":"markdown","metadata":{"id":"WMJUMe4bHkLR"},"source":["### *Load the dataset using chunk*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QerPcf7Iu-ym"},"outputs":[],"source":["chunksize = 150\n","k = 1\n","for file in dir_list:\n","  print('============================================================================')\n","  print('WORKING ON FILE NUMBER: {:d}'.format(k))\n","\n","  i = 1\n","\n","  with pd.read_csv(path_name + '/' + file, sep='|', header=None, index_col = None, \n","                  names=[\"Spectrum_Data\", \"Cell_Parameters\", \"Volume\", \n","                          \"ID_Observations\", \"Crystal_Structure_Type\"], \n","                  chunksize=chunksize, usecols = [0,1,2,3,4]) as reader:\n","                  for chunk in reader:\n","                    print('----------------------------------------------------------------------------')\n","                    print('Working of chunk number: {:d}'.format(i))\n","                    print('----------------------------------------------------------------------------')\n","                    print(\"DataType: {} \\nShape: {} \\nMemory: {}\".format(type(chunk),\n","                                                chunk.shape, \n","                                                chunk.memory_usage().sum()))\n","                    \n","                    # Retrive field for additional_information_dataset dataframe\n","                    chunk[['a', 'b', 'c', 'alpha', 'beta', 'gamma',]] = chunk.Cell_Parameters.str.split(' ', expand=True)\n","                    chunk.pop('Cell_Parameters')\n","                    additional_information_single_chunk = chunk[['ID_Observations', \n","                                                                  'a', 'b', 'c', \n","                                                                  'alpha', 'beta',\n","                                                                  'gamma', 'Volume',\n","                                                                  'Crystal_Structure_Type']]\n","                    additional_information_dataset = pd.concat([additional_information_dataset, \n","                                                                additional_information_single_chunk], ignore_index= True)\n","                    \n","                    # Retrive and split specrtum field\n","                    xy_chunk = chunk['Spectrum_Data'].str.split(' ', expand=True)\n","                    x_y_chunk = pd.DataFrame()\n","\n","                    j = 1\n","                    for col in xy_chunk.columns:\n","                      x_y_chunk[[f'x_{j}', f'y_{j}']] = xy_chunk[col].str.split(';', expand = True)\n","                      j = j + 1\n","\n","                    # Drop column with name starting with 'x_'\n","                    x_y_chunk = x_y_chunk.loc[:, ~x_y_chunk.columns.str.contains('^x_')]\n","                                        \n","                    x_y_chunk['ID_Observations'] = chunk.ID_Observations\n","\n","                    y_coord_dataset = pd.concat([y_coord_dataset, x_y_chunk], ignore_index= True)\n","                    \n","                    i = i + 1\n","  k = k + 1"]},{"cell_type":"code","source":["additional_information_dataset=additional_information_dataset.set_index('ID_Observations')\n","y_coord_dataset=y_coord_dataset.set_index('ID_Observations')"],"metadata":{"id":"mLfl7Sd2XwIL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hnquzXhUCAeW"},"outputs":[],"source":["print('x_coord_dataset shape: {}'.format(x_coord_dataset.shape))\n","print('x_coord_dataset data types: \\n{}'.format(x_coord_dataset.dtypes))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JJcwoQNuxKC"},"outputs":[],"source":["print('y_coord_dataset shape: {}'.format(y_coord_dataset.shape))\n","print('y_coord_dataset data types: \\n{}'.format(y_coord_dataset.dtypes))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImGLUywV3a52"},"outputs":[],"source":["print('additional_information_dataset shape: {}'.format(additional_information_dataset.shape))\n","print('additional_information_dataset data types: \\n{}'.format(additional_information_dataset.dtypes))"]},{"cell_type":"markdown","metadata":{"id":"rK4h-wgHCJ3f"},"source":["## Basic checks"]},{"cell_type":"markdown","metadata":{"id":"-m2fya6IFHSf"},"source":["### *Casting of numeric field from object to float*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJMPPMqcFj8p"},"outputs":[],"source":["y_coord_dataset = y_coord_dataset.apply(pd.to_numeric)\n","print('y_coord_dataset data types after casting operation: \\n{}'.format(y_coord_dataset.dtypes))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4u7SXOPuoTN"},"outputs":[],"source":["index_name = additional_information_dataset.select_dtypes(include='object').columns\n","index_name = index_name.drop('Crystal_Structure_Type')\n","additional_information_dataset[index_name] = additional_information_dataset[index_name].apply(pd.to_numeric)\n","print('additional_information_dataset data types after casting operation: \\n{}'.format(additional_information_dataset.dtypes))"]},{"cell_type":"markdown","metadata":{"id":"LI-A7lzGI5kO"},"source":["### *Merging additional_information_dataset and y_coord_dataset on ID_Observations*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zm6rMXqLGhpV"},"outputs":[],"source":["y_coord_dataset = y_coord_dataset.join(additional_information_dataset)\n","print('y_coord_dataset shape: {}'.format(y_coord_dataset.shape))\n","print('y_coord_dataset data types: \\n{}'.format(y_coord_dataset.dtypes))"]},{"cell_type":"markdown","metadata":{"id":"gc2hiJQ0KY6N"},"source":["### *Check for ***null*** field*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WswbRfYGht1"},"outputs":[],"source":["print('Null field in y_coord_dataset: \\n{}'.format(y_coord_dataset.isnull().any()))\n","sns.heatmap(y_coord_dataset.isnull(), cbar=False)"]},{"cell_type":"markdown","metadata":{"id":"mLbCiwTrVp5I"},"source":["### *Check for NaN rows and drop it*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QhpOjCf4VqOD"},"outputs":[],"source":["n_samples = y_coord_dataset.shape[0]\n","y_coord_dataset = y_coord_dataset.dropna()   \n","print('Number of NaN rows dropped: {}/{} ({:.2f}%)'.format(n_samples - y_coord_dataset.shape[0], n_samples, (n_samples - y_coord_dataset.shape[0]) / n_samples * 100))"]},{"cell_type":"markdown","metadata":{"id":"CQUkwEcON_33"},"source":["### *Check for duplicate rows and drop, if exists*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EZsG5FEGhz9"},"outputs":[],"source":["duplicated_rows = y_coord_dataset[y_coord_dataset.duplicated()]\n","n_samples = y_coord_dataset.shape[0]  \n","duplicates = n_samples - y_coord_dataset.shape[0]\n","\n","if not duplicated_rows.empty:\n","  y_coord_dataset.drop_duplicates(ignore_index=False, inplace=True)\n","  print('Number of canceled duplicates: {}/{} ({:.2f}%)'.format(duplicates, n_samples, duplicates / n_samples * 100))\n","else:\n","  print('Number of canceled duplicates: {}/{} ({:.2f}%)'.format(duplicates, n_samples, duplicates / n_samples * 100))"]},{"cell_type":"markdown","metadata":{"id":"DEtPlW9HkBXi"},"source":["## Show dataset content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2D7kNfz0kGvx"},"outputs":[],"source":["print('x_coord_dataset content: ')\n","x_coord_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBwUKThXkG9W"},"outputs":[],"source":["print('y_coord_dataset content: ')\n","y_coord_dataset"]},{"cell_type":"markdown","metadata":{"id":"Q15HrR3le2eT"},"source":["## Saving the new dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXKJKZE0Gh6A"},"outputs":[],"source":["def save_dataset(dataset):\n","  save_data = input('Do you want to save x_coord_dataset [y|n]: ')\n","  if save_data.lower() == 'y':\n","    path_dataset = input('Enter path in which to store dataset: ')\n","    name_dataset = input('Enter dataset name you want to save: ')\n","    valid_dataset_path = '/content/' + path_dataset\n","\n","    if os.path.exists(valid_dataset_path):\n","      complete_path = valid_dataset_path + '/' + name_dataset + '.csv'\n","      dataset.to_csv(complete_path, sep=';', index=True, header=True)\n","      print('Dataset stored in : ',complete_path)\n","    else:\n","      print('Error! Invalid name of dataset or Not uploaded dataset has been requested.\\n'\n","            +'Please, enter a valid dataset name to continue.')\n","  elif save_data.lower() == 'n':\n","    print('Dataset will NOT be saved!')"]},{"cell_type":"markdown","metadata":{"id":"FiB1Rv3ijajJ"},"source":["### *Saving x_coord_dataset*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkVMD16TiVHi"},"outputs":[],"source":["save_dataset(x_coord_dataset)"]},{"cell_type":"markdown","metadata":{"id":"iJkSYlDxjgzk"},"source":["### *Saving y_coord_dataset*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0He7L3bHjnU0"},"outputs":[],"source":["save_dataset(y_coord_dataset)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMmm4wcMAF0ooSCtdvwJit"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}